{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from C:\\Users\\MITLAB\\python_project\\itri_backup\\5G-Coverage-Detector\\src\\function_set\\helper.ipynb\n",
      "importing Jupyter notebook from C:\\Users\\MITLAB\\python_project\\itri_backup\\5G-Coverage-Detector\\src\\model\\model.ipynb\n"
     ]
    }
   ],
   "source": [
    "import function_set.loadnotebook\n",
    "\n",
    "import os\n",
    "import math\n",
    "import copy\n",
    "import traceback\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import matplotlib.cm as cm\n",
    "import pickle\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.svm import SVR, SVC\n",
    "from functools import partial\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = '1'\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "device\n",
    "\n",
    "from function_set.helper import * \n",
    "from model.model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport argparse\\nparser = argparse.ArgumentParser()\\nparser.add_argument(\"-s\", \"--source\", type=str,\\n                    help=\"Please input source type [\\'UJIdataset\\', \\'ITRI-indoor\\', \\'ITRI-outdoor\\']\")\\nparser.add_argument(\"--indoor-set\", type=int,\\n                    help=\"Indoor power config  set\")\\nargs = parser.parse_args()'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import argparse\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"-s\", \"--source\", type=str,\n",
    "                    help=\"Please input source type [\\'UJIdataset\\', \\'ITRI-indoor\\', \\'ITRI-outdoor\\']\")\n",
    "parser.add_argument(\"--indoor-set\", type=int,\n",
    "                    help=\"Indoor power config  set\")\n",
    "args = parser.parse_args()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SignalDetector:\n",
    "    def get_dataset_source(self, source):\n",
    "        if source == 'UJIdataset':\n",
    "            self.source = source\n",
    "            self.data_dir = '../data/UJIIndoorLoc/restructured_train.csv'\n",
    "        elif source == 'ITRI-indoor':\n",
    "            self.source = source\n",
    "            self.data_dir = '../data/ITRI-indoor/restructed_csv/all_summary.csv'\n",
    "        elif source == 'ITRI-outdoor':\n",
    "            self.source = source\n",
    "            self.data_dir = '../data/ITRI-outdoor/restructed_csv/restructed.csv'\n",
    "        else:\n",
    "            print('- Please input \\'UJIdataset\\', \\'ITRI-indoor\\' or \\'ITRI-outdoor\\' and other dataset are not surppoted yet. -')\n",
    "    def __init__(self, source):\n",
    "        #define source\n",
    "        self.get_dataset_source(source)\n",
    "        \n",
    "        #read csv data(have to restruct first)\n",
    "        self.df = pd.read_csv(self.data_dir)\n",
    "\n",
    "        #turn coodinate to range (-1, 1)\n",
    "        self.df['LONGITUDE'] = minmax_scale(self.df['LONGITUDE'], feature_range=(-1, 1))\n",
    "        self.df['LATITUDE'] = minmax_scale(self.df['LATITUDE'], feature_range=(-1, 1))\n",
    "\n",
    "        #Here, LL means Longitude and Latidue, S means set, W means WAP. This is used to choose certain collumns of df\n",
    "        LLSW = LLS + ['WAP']\n",
    "\n",
    "        #replace signal 100 as -100\n",
    "        self.df['SIGNAL'].replace(100, -100, inplace=True)\n",
    "        #turn signal to range (-1,1)\n",
    "        self.df['SIGNAL'] = minmax_scale(self.df['SIGNAL'], feature_range=(-1, 1))\n",
    "        #mark out the minimum signal at each location\n",
    "        self.df_agg_max_all_set = merge_agg(self.df, LLSW, 'SIGNAL', ['min'], ['MIN_SIGNAL'])\n",
    "        \n",
    "    def set_s(self, s):\n",
    "        if self.source == 'ITRI-indoor':\n",
    "            self.s = s\n",
    "        else:\n",
    "            print('- Set is not supported in this dataset -')\n",
    "        \n",
    "    def encoder_result(self, lr=1e-1, lr_decay=1e-1, \n",
    "                   lr_decay_epoch=5, weight_decay=1e-5, show=False, s = None) :\n",
    "    \n",
    "        train_dataloader, val_dataloader = get_loader(self.df_train, self.df_val)\n",
    "\n",
    "        model, criterion, optimizer = get_model(num_epochs=100, \n",
    "                                                lr=lr, lr_decay=lr_decay,\n",
    "                                                weight_decay=weight_decay,  \n",
    "                                                lr_decay_epoch=int(lr_decay_epoch))\n",
    "\n",
    "        best_model = train(model, criterion, optimizer, \n",
    "                           train_dataloader,\n",
    "                           num_epochs=100, \n",
    "                           show=show, s = self.s)\n",
    "\n",
    "        #signal LLW\n",
    "        distance = evaluate(best_model, self.df_val)\n",
    "        mse = mean_squared_error(self.df_val['DIFF_SIGNAL'], distance)\n",
    "\n",
    "        if not show :\n",
    "            return -mse\n",
    "\n",
    "        train_distance = evaluate(best_model, self.df_train)\n",
    "        detected = self.df_train[(self.df_train.SIGNAL>-1)].index.values\n",
    "        max_distance = 0.1*train_distance[detected].max()\n",
    "\n",
    "        # coverage LLW\n",
    "        covered = distance<max_distance\n",
    "        c_acc = np.mean((self.df_val['SIGNAL'] > -1) == covered)\n",
    "\n",
    "        df_llw = self.df_val.copy()\n",
    "        df_llw['distance'] = distance\n",
    "        df_llw['covered'] = covered\n",
    "\n",
    "        generated_distance = evaluate(best_model, self.val_generated)\n",
    "        self.val_generated['pred_COVERAGE'] = (generated_distance<max_distance).astype(int)\n",
    "        generated_coverage = self.val_generated.groupby(LL)['pred_COVERAGE'].sum().reset_index()\n",
    "\n",
    "        # coverage LL\n",
    "        df_ll = self.df_val_per_locs.merge(generated_coverage, on=LL)\n",
    "        c_mse = mean_squared_error(df_ll['COVERAGE'], df_ll['pred_COVERAGE'])\n",
    "\n",
    "        if self.pollute_happened:\n",
    "            # pilot pollution LL\n",
    "            df_ll['pred_POLLUTED'] = df_ll['pred_COVERAGE'] > 1\n",
    "            p_acc = np.mean(((df_ll['STATUS']==2) == df_ll['pred_POLLUTED']))\n",
    "\n",
    "        # hole LL      \n",
    "        df_ll['pred_HOLE'] = df_ll['pred_COVERAGE'] == 0\n",
    "        h_acc = np.mean(((df_ll['STATUS']==0) == df_ll['pred_HOLE']))\n",
    "\n",
    "        if self.pollute_happened:\n",
    "            #todo coverage mse and coverage acc\n",
    "            print('encoder', 'mse signal LLW', mse, 'coverage LLW', c_acc) \n",
    "            print('coverage LL', c_mse, 'acc polluted LL', p_acc, 'hole LL', h_acc)\n",
    "            json_data = {'encoder': {'mse signal LLW': mse, \n",
    "                                     'coverage LLW': c_acc,\n",
    "                                    'coverage LL': c_mse,\n",
    "                                     'acc polluted LL': p_acc,\n",
    "                                     'hole LL': h_acc}}\n",
    "            json_data = json.dumps(json_data)\n",
    "            with open(json_dir+'AE.json', 'w') as f:\n",
    "                f.write(json_data)\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            print('encoder', 'mse signal LLW', mse, 'coverage LLW', c_acc) \n",
    "            print('coverage LL', c_mse, 'hole LL', h_acc)\n",
    "            json_data = {'encoder': {'mse signal LLW': mse, \n",
    "                                     'coverage LLW': c_acc,\n",
    "                                    'coverage LL': c_mse,\n",
    "                                     'hole LL': h_acc}}\n",
    "            json_data = json.dumps(json_data)\n",
    "            with open(json_dir+'AE.json', 'w') as f:\n",
    "                f.write(json_data)\n",
    "\n",
    "        dir = \"..\\\\results\\\\model\"\n",
    "        torch.save(best_model.state_dict(),os.path.join(dir,\"AE_set\" + str(self.s) + \"_model.pth\"))\n",
    "        print(\"- Model has been SAVED! -\")\n",
    "\n",
    "        return df_llw, df_ll\n",
    "\n",
    "    def optimize_encoder(self):\n",
    "        encoder_fn = partial(self.encoder_result)\n",
    "\n",
    "        optimizer = BayesianOptimization(\n",
    "            f=encoder_fn,\n",
    "            pbounds={\"lr\": (1e-3, 5e-1), \n",
    "                     \"lr_decay\": (1e-5, 5e-1), \n",
    "                     \"lr_decay_epoch\": (5, 50), \n",
    "                     \"weight_decay\": (1e-5, 5e-1)},\n",
    "            random_state=2,\n",
    "            verbose=2\n",
    "        )\n",
    "        optimizer.maximize(n_iter=3)\n",
    "        return optimizer\n",
    "    \n",
    "    def get_data_train_val(self):\n",
    "        try:\n",
    "            #filter out the set data,         \n",
    "            data = get_train_val(self.s, self.df_agg_max_all_set)\n",
    "            self.df_train_per_locs, self.df_val_per_locs, self.df_train, self.df_val, self.val_generated, self.pollute_happened = data\n",
    "            \n",
    "            del data\n",
    "            \n",
    "            plot_data(self.df_train_per_locs, self.df_val_per_locs)\n",
    "        except Exception :\n",
    "            traceback.print_exc()\n",
    "            \n",
    "    def train_AE(self):\n",
    "        try:\n",
    "            self.opt = self.optimize_encoder()\n",
    "            self.enc_preds = self.encoder_result(show=True, **self.opt.max['params'], s=self.s)\n",
    "            \n",
    "        except Exception :\n",
    "            traceback.print_exc()\n",
    "    def train_KNN(self):\n",
    "        try:\n",
    "            self.knn_signal = KNeighborsRegressor(n_neighbors=4)\n",
    "            self.knn_coverage = KNeighborsClassifier(n_neighbors=4)\n",
    "            self.knn_coverage2 = KNeighborsRegressor(n_neighbors=4)\n",
    "            self.knn_polluted = KNeighborsClassifier(n_neighbors=4)\n",
    "            self.knn_hole = KNeighborsClassifier(n_neighbors=4)\n",
    "            \n",
    "            self.knn_preds = other_result('knn', self.knn_signal, \n",
    "                                     self.knn_coverage, self.knn_coverage2, \n",
    "                                     self.knn_polluted, self.knn_hole, \n",
    "                                     self.df_train, self.df_val, \n",
    "                                     self.df_train_per_locs, self.df_val_per_locs, self.pollute_happened, self.s)\n",
    "        except Exception :\n",
    "            traceback.print_exc()\n",
    "            \n",
    "    def train_SVM(self):\n",
    "        try:\n",
    "            self.svm_signal = SVR(gamma='scale')\n",
    "            self.svm_coverage = SVC(gamma='scale')\n",
    "            self.svm_coverage2 = SVR(gamma='scale')\n",
    "            self.svm_polluted = SVC(gamma='scale')\n",
    "            self.svm_hole = SVC(gamma='scale')\n",
    "            self.svm_preds = other_result('svm', self.svm_signal, \n",
    "                                     self.svm_coverage, self.svm_coverage2, \n",
    "                                     self.svm_polluted, self.svm_hole, \n",
    "                                     self.df_train, self.df_val, \n",
    "                                     self.df_train_per_locs, self.df_val_per_locs, self.pollute_happened, self.s)\n",
    "        except Exception :\n",
    "            traceback.print_exc()\n",
    "            \n",
    "    def train_DT(self):\n",
    "        try:\n",
    "            self.dt_signal = DecisionTreeRegressor()\n",
    "            self.dt_coverage = DecisionTreeClassifier()\n",
    "            self.dt_coverage2 = DecisionTreeClassifier()\n",
    "            self.dt_polluted = DecisionTreeClassifier()\n",
    "            self.dt_hole = DecisionTreeClassifier()\n",
    "            self.dt_preds = other_result('dt', self.dt_signal, \n",
    "                                     self.dt_coverage, self.dt_coverage2, \n",
    "                                     self.dt_polluted, self.dt_hole, \n",
    "                                     self.df_train, self.df_val, \n",
    "                                     self.df_train_per_locs, self.df_val_per_locs, self.pollute_happened, self.s)\n",
    "        except Exception :\n",
    "            traceback.print_exc()\n",
    "        \n",
    "    def plot_result(self):\n",
    "        if not hasattr(self, 'df_val_per_locs'):\n",
    "            print('- Plese do get_data_train_vals(). -')\n",
    "        elif not hasattr(self, 'enc_preds'):\n",
    "            print('- Plese do train_AE(). -')\n",
    "        elif not hasattr(self, 'knn_preds'):\n",
    "            print('- Plese do train_KNN(). -')\n",
    "        elif not hasattr(self, 'svm_preds'):\n",
    "            print('- Plese do train_SVM(). -')\n",
    "        elif not hasattr(self, 'dt_preds'):\n",
    "            print('- Plese do train_DT(). -')\n",
    "            \n",
    "        else:\n",
    "            try:\n",
    "                if self.pollute_happened:\n",
    "                    for t in [ 'coverage', 'polluted', 'hole'] :\n",
    "                        fig = plt.figure(figsize=(25,15))\n",
    "                        plot_encoder(1, self.enc_preds, plot_type=t)\n",
    "                        plot_other(2, self.df_val_per_locs, self.knn_preds, 'knn', self.pollute_happened, plot_type=t)\n",
    "                        plot_other(3, self.df_val_per_locs, self.svm_preds, 'svm', self.pollute_happened, plot_type=t)\n",
    "                        plot_other(4, self.df_val_per_locs, self.dt_preds, 'dt', self.pollute_happened, plot_type=t)\n",
    "                        plt.show()\n",
    "\n",
    "                    _, df_ll = self.enc_preds\n",
    "                    y_true = df_ll['STATUS']==2\n",
    "                    y_pred_enc = df_ll['pred_POLLUTED']\n",
    "                    y_pred_knn = self.knn_preds[3]\n",
    "                    y_pred_dt = self.dt_preds[3]\n",
    "                    y_pred_svm = self.svm_preds[3]\n",
    "\n",
    "                    print(\"-------------------------Pollution-----------------------------\")\n",
    "                    print(\"AE F1-score: \",f1_score(y_true, y_pred_enc))\n",
    "                    print(\"KNN F1-score: \",f1_score(y_true, y_pred_knn))\n",
    "                    print(\"DT F1-score: \",f1_score(y_true, y_pred_dt))\n",
    "                    print(\"SVM F1-score: \",f1_score(y_true, y_pred_svm))\n",
    "                    print(\"--------------------------Pollution----------------------------\")\n",
    "                    print(\"AE recall score: \", recall_score(y_true, y_pred_enc))\n",
    "                    print(\"KNN recall score: \", recall_score(y_true, y_pred_knn))\n",
    "                    print(\"DT recall score: \", recall_score(y_true, y_pred_dt))\n",
    "                    print(\"SVM recall score: \", recall_score(y_true, y_pred_svm))\n",
    "                    print(\"-----------------------Pollution-------------------------------\")\n",
    "                else:\n",
    "                    for t in [ 'coverage', 'hole'] :\n",
    "                        fig = plt.figure(figsize=(25,15))\n",
    "                        plot_encoder(1, self.enc_preds, plot_type=t)\n",
    "                        plot_other(2, self.df_val_per_locs, self.knn_preds, 'knn', self.pollute_happened, plot_type=t)\n",
    "                        plot_other(3, self.df_val_per_locs, self.svm_preds, 'svm', self.pollute_happened, plot_type=t)\n",
    "                        plot_other(4, self.df_val_per_locs, self.dt_preds, 'dt', self.pollute_happened, plot_type=t)\n",
    "                        plt.show()\n",
    "\n",
    "                _, df_ll = self.enc_preds\n",
    "                y_true = df_ll['STATUS']==0\n",
    "                y_pred_enc = df_ll['pred_HOLE']\n",
    "                if self.pollute_happened:\n",
    "                    y_pred_knn = self.knn_preds[4]\n",
    "                    y_pred_dt = self.dt_preds[4]\n",
    "                    y_pred_svm = self.svm_preds[4]\n",
    "                else:\n",
    "                    y_pred_knn = self.knn_preds[3]\n",
    "                    y_pred_dt = self.dt_preds[3]\n",
    "                    y_pred_svm = self.svm_preds[3]\n",
    "\n",
    "                print(\"-------------------------HOLE-----------------------------\")\n",
    "                print(\"AE F1-score: \",f1_score(y_true, y_pred_enc))\n",
    "                print(\"KNN F1-score: \",f1_score(y_true, y_pred_knn))\n",
    "                print(\"DT F1-score: \",f1_score(y_true, y_pred_dt))\n",
    "                print(\"SVM F1-score: \",f1_score(y_true, y_pred_svm))\n",
    "                print(\"--------------------------HOLE----------------------------\")\n",
    "                print(\"AE recall score: \", recall_score(y_true, y_pred_enc))\n",
    "                print(\"KNN recall score: \", recall_score(y_true, y_pred_knn))\n",
    "                print(\"DT recall score: \", recall_score(y_true, y_pred_dt))\n",
    "                print(\"SVM recall score: \", recall_score(y_true, y_pred_svm))\n",
    "                print(\"-----------------------HOLE-------------------------------\")\n",
    "            except Exception :\n",
    "                traceback.print_exc()\n",
    "            \n",
    "    def do_experiment(self) :\n",
    "        self.get_data_train_val()\n",
    "        self.train_AE()\n",
    "        self.train_KNN()\n",
    "        self.train_SVM()\n",
    "        self.train_DT()\n",
    "        self.plot_result()\n",
    "        \n",
    "\n",
    "        \n",
    "def __main__():\n",
    "    MySD = SignalDetector('ITRI-indoor')\n",
    "    MySD.set_s(5)\n",
    "    MySD.get_data_train_val()\n",
    "    try:\n",
    "        MySD.train_AE()\n",
    "    except Exception:\n",
    "        MySD.train_AE()\n",
    "    #MySD.train_KNN()\n",
    "    #MySD.train_SVM()\n",
    "    #MySD.train_DT()\n",
    "    #MySD.plot_result()      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |    lr     | lr_decay  | lr_dec... | weight... |\n",
      "-------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-0.5773  \u001b[0m | \u001b[0m 0.2186  \u001b[0m | \u001b[0m 0.01297 \u001b[0m | \u001b[0m 29.73   \u001b[0m | \u001b[0m 0.2177  \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m-0.7491  \u001b[0m | \u001b[0m 0.2108  \u001b[0m | \u001b[0m 0.1652  \u001b[0m | \u001b[0m 14.21   \u001b[0m | \u001b[0m 0.3096  \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m-0.6481  \u001b[0m | \u001b[0m 0.1505  \u001b[0m | \u001b[0m 0.1334  \u001b[0m | \u001b[0m 32.95   \u001b[0m | \u001b[0m 0.2646  \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m-0.702   \u001b[0m | \u001b[0m 0.06816 \u001b[0m | \u001b[0m 0.2568  \u001b[0m | \u001b[0m 13.3    \u001b[0m | \u001b[0m 0.3927  \u001b[0m |\n",
      "| \u001b[95m 5       \u001b[0m | \u001b[95m-0.2885  \u001b[0m | \u001b[95m 0.4271  \u001b[0m | \u001b[95m 0.2471  \u001b[0m | \u001b[95m 43.1    \u001b[0m | \u001b[95m 0.03983 \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m-1.043   \u001b[0m | \u001b[0m 0.001   \u001b[0m | \u001b[0m 1e-05   \u001b[0m | \u001b[0m 50.0    \u001b[0m | \u001b[0m 0.5     \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m-0.5985  \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 1e-05   \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 1e-05   \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m-1.746   \u001b[0m | \u001b[0m 0.001   \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 39.82   \u001b[0m | \u001b[0m 0.5     \u001b[0m |\n",
      "=========================================================================\n",
      "Set 5 model loss start 1.1551 best 0.1200\n",
      "encoder mse signal LLW 0.2873420027104248 coverage LLW 0.8703703703703703\n",
      "coverage LL 5.148148148148148 acc polluted LL 0.7962962962962963 hole LL 0.2777777777777778\n",
      "- Model has been SAVED! -\n"
     ]
    }
   ],
   "source": [
    "__main__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
